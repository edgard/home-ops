---
defaultPodOptions:
  securityContext:
    fsGroup: 1000
    fsGroupChangePolicy: OnRootMismatch
    runAsGroup: 1000
    runAsNonRoot: true
    runAsUser: 1000

controllers:
  main:
    type: deployment
    replicas: 1
    strategy: Recreate
    serviceAccount:
      identifier: litellm
    annotations:
      reloader.stakater.com/auto: "true"
    containers:
      app:
        image:
          repository: ghcr.io/berriai/litellm
          tag: v1.80.11-stable
        args:
          - "--config"
          - "/app/config.yaml"
        env:
          PORT: "4000"
          GITHUB_COPILOT_TOKEN_DIR: "/app/github-copilot-tokens"
        envFrom:
          - secretRef:
              name: litellm-credentials
        probes:
          startup:
            enabled: true
          liveness:
            enabled: true
          readiness:
            enabled: true
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
              - ALL
        resources: {}
      mcp-kubernetes:
        image:
          repository: flux159/mcp-server-kubernetes
          tag: v3.2.0
        env:
          ENABLE_UNSAFE_STREAMABLE_HTTP_TRANSPORT: "1"
          PORT: "3002"
          HOST: "0.0.0.0"
          ALLOW_ONLY_READONLY_TOOLS: "true"
          MASK_SECRETS: "true"
          SPAWN_MAX_BUFFER: "10485760"
        probes:
          startup:
            enabled: true
            port: 3002
          liveness:
            enabled: true
            port: 3002
          readiness:
            enabled: true
            port: 3002
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
              - ALL
        resources: {}
      mcp-n8n:
        image:
          repository: ghcr.io/czlonkowski/n8n-mcp
          tag: "2.33.2"
        env:
          MCP_MODE: "http"
          PORT: "3003"
          HOST: "0.0.0.0"
          LOG_LEVEL: "error"
          NODE_ENV: "production"
          AUTH_TOKEN: "internal-sidecar-token"
          AUTH_RATE_LIMIT_WINDOW: "60000"
          AUTH_RATE_LIMIT_MAX: "1000"
          N8N_MCP_TELEMETRY_DISABLED: "true"
          N8N_API_URL: "https://n8n.edgard.org"
          N8N_API_KEY:
            valueFrom:
              secretKeyRef:
                name: litellm-credentials
                key: MCP_N8N_API_KEY
        probes:
          startup:
            enabled: true
            port: 3003
          liveness:
            enabled: true
            port: 3003
          readiness:
            enabled: true
            port: 3003
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
              - ALL
        resources: {}

serviceAccount:
  litellm:
    enabled: true

service:
  main:
    controller: main
    type: ClusterIP
    annotations:
      gatus.edgard.org/enabled: "true"
    ports:
      http:
        enabled: true
        port: 80
        targetPort: 4000

route:
  main:
    parentRefs:
      - name: gateway
        namespace: platform-system
        sectionName: https
    hostnames:
      - litellm.edgard.org
    rules:
      - backendRefs:
          - identifier: main
            port: 80

persistence:
  config:
    type: configMap
    identifier: config
    advancedMounts:
      main:
        app:
          - path: /app/config.yaml
            subPath: config.yaml
  github-copilot-tokens:
    type: persistentVolumeClaim
    accessMode: ReadWriteOnce
    size: 100Mi
    storageClass: nfs-fast
    retain: true
    advancedMounts:
      main:
        app:
          - path: /app/github-copilot-tokens

configMaps:
  config:
    data:
      config.yaml: |-
        general_settings:
          master_key: os.environ/LITELLM_MASTER_KEY

        litellm_settings:
          drop_params: true
          num_retries: 3
          telemetry: false
          cache: true
          cache_params:
            type: local
            ttl: 3600

        model_list:
          - model_name: gpt-5-mini
            litellm_params:
              model: github_copilot/gpt-5-mini
              extra_headers:
                User-Agent: "GitHubCopilotChat/0.26.7"
                Editor-Version: "vscode/1.99.3"
                Editor-Plugin-Version: "copilot-chat/0.26.7"
                Copilot-Integration-Id: "vscode-chat"

          - model_name: gpt-5.2
            litellm_params:
              model: github_copilot/gpt-5.2
              extra_headers:
                User-Agent: "GitHubCopilotChat/0.26.7"
                Editor-Version: "vscode/1.99.3"
                Editor-Plugin-Version: "copilot-chat/0.26.7"
                Copilot-Integration-Id: "vscode-chat"

        mcp_servers:
          github:
            url: "https://api.githubcopilot.com/mcp"
            transport: "http"
            auth_type: "bearer_token"
            auth_value: "os.environ/MCP_GITHUB_TOKEN"
            description: "GitHub - Repositories, issues, PRs, and code"
          kubernetes:
            url: "http://127.0.0.1:3002/mcp"
            transport: "http"
            description: "Kubernetes - Cluster resources (read-only)"
          n8n:
            url: "http://127.0.0.1:3003/mcp"
            transport: "http"
            static_headers:
              Authorization: "Bearer internal-sidecar-token"
            description: "n8n - Workflow automation"
          context7:
            url: "https://mcp.context7.com/mcp"
            transport: "http"
            static_headers:
              CONTEXT7_API_KEY: "os.environ/MCP_CONTEXT7_API_KEY"
            description: "Context7 - Library documentation"
          grep:
            url: "https://mcp.grep.app"
            transport: "http"
            description: "Grep.app - GitHub code search"
          exa:
            url: "https://mcp.exa.ai/mcp?tools=web_search_exa,deep_search_exa,crawling"
            transport: "http"
            description: "Exa AI - Web search"
